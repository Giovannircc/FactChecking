{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUV6D0GxAJf"
      },
      "source": [
        "# Dashboard Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpi9KvSkXk5m"
      },
      "source": [
        "### Guida utilizzo di Streamlit mediante Colab:\n",
        "1. Eseguire la cella contenente i Pip Install necessari\n",
        "2. Eseguire la cella che genera il file dashboard.py\n",
        "3. Eseguire la cella per generare la password di localtunnel.\n",
        "2. Copiare la password una volta prodotta in output.\n",
        "3. Eseguire l'ultima cella e cliccare sul link (Es \"ninety-times-cut.loca.lt/\"o simili)\n",
        "4. In caso di \"Service Unavailable\", stoppare l'ultima cella e runnare nuovamente.\n",
        "5. Inserire nello spazio vuoto la password copiata in precedenza.\n",
        "6. Attendere il caricamento del modello nella dashboard.\n",
        "7. Enjoy\n",
        "\n",
        "**NB**: Il caricamento del modello al primo lancio potrebbe avere un tempo stimato di una decina di minuti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzt-xVikXghN"
      },
      "source": [
        "### Pip Install Necessari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t1ugwcB44ndo",
        "outputId": "ceaaf0a8-d847-45c4-9cc0-65b737c85708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/547.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/547.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/547.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dnspython, dill, pymongo, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, sentence_transformers\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 dnspython-2.6.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyarrow-16.1.0 pymongo-4.7.3 requests-2.32.3 sentence_transformers-3.0.1 xxhash-3.4.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes, accelerate\n",
            "Successfully installed accelerate-0.31.0 bitsandbytes-0.43.1\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 watchdog-4.0.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.3.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting it-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.7.0/it_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets pandas pymongo sentence_transformers\n",
        "!pip install -U transformers\n",
        "!pip install bitsandbytes accelerate\n",
        "!pip install streamlit\n",
        "!pip install spacy plotly\n",
        "!python -m spacy download it_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx-f6bYTXbjf"
      },
      "source": [
        "## Scrittura ed Avvio Dashboard.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generazione del file .py"
      ],
      "metadata": {
        "id": "qTebRzfJT0wt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boDgRd491rR4",
        "outputId": "229c9ac8-fe93-4854-ce34-2780c6ce938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dashboard.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dashboard.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import spacy\n",
        "import plotly.express as px\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@st.cache_resource\n",
        "def create_mongo_client():\n",
        "    uri = \"mongodb+srv://giovannircc99:Napoli99!@clusterbigdata.1rjiesw.mongodb.net/?retryWrites=true&w=majority&appName=ClusterBigData\"\n",
        "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "    try:\n",
        "        client.admin.command('ping')\n",
        "        print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return client\n",
        "\n",
        "client = create_mongo_client()\n",
        "\n",
        "db = client['factChecking']\n",
        "collection = db['articles']\n",
        "\n",
        "@st.cache_resource\n",
        "def load_spacy_model():\n",
        "    return spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "def extract_journalist_names(authors_list):\n",
        "    \"\"\"\n",
        "    This function takes a list of authors and extracts journalist names.\n",
        "    Args:\n",
        "    - authors_list (list of str): List containing author strings.\n",
        "\n",
        "    Returns:\n",
        "    - extracted_names (list of list of str): List of extracted journalist names.\n",
        "    \"\"\"\n",
        "    if not isinstance(authors_list, list):\n",
        "        raise TypeError(\"authors_list should be a list of authors' names.\")\n",
        "\n",
        "    extracted_names = []\n",
        "    name_pattern = re.compile(r'^[A-Z][a-z]+ [A-Z][a-z]+$')\n",
        "    exclude_keywords = {'Editoriale','Redazione','Web','a cura di', 'con supporto di', 'per segnalazioni sul contenuto del servizio','Redazione Web'}\n",
        "\n",
        "    for author in authors_list:\n",
        "        if isinstance(author, float) and pd.isna(author):  # Check for NaN\n",
        "            continue\n",
        "\n",
        "        if not isinstance(author, str):\n",
        "            author = str(author)  # Convert non-string types to string\n",
        "\n",
        "        # Process the author string using spaCy\n",
        "        doc = nlp(author)\n",
        "        names = set()  # Use a set to avoid duplicates\n",
        "        # Extract names using spaCy\n",
        "        for entity in doc.ents:\n",
        "            if entity.label_ == \"PER\" and entity.text not in exclude_keywords:  # Check if the entity is a person\n",
        "                names.add(entity.text)\n",
        "        # Extract names using regex\n",
        "        for token in author.split(','):\n",
        "            token = token.strip()\n",
        "            if name_pattern.match(token) and token not in exclude_keywords:\n",
        "                names.add(token)\n",
        "        extracted_names.append(list(names))\n",
        "\n",
        "    return extracted_names\n",
        "\n",
        "# Funzione per caricare il database e i dati necessari\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    # Estrazione degli articoli\n",
        "    #articles = list(collection.find())\n",
        "    print(\"START LOAD DATA\")\n",
        "    articles = list(collection.find({}, {'publish_date': 1, 'text': 1, 'title': 1}))\n",
        "    print(\"caricamento articles completato\")\n",
        "    # Estrazione delle date di pubblicazione\n",
        "    publish_dates = [article['publish_date'] for article in articles if 'publish_date' in article]\n",
        "    publish_dates = pd.to_datetime(publish_dates)\n",
        "    publish_date_counts = publish_dates.value_counts().sort_index()\n",
        "    print(\"caricamento publish date completato\")\n",
        "    # Estrazione dei titoli\n",
        "    titles = [article['title'] for article in articles if 'title' in article]\n",
        "    text = ' '.join(titles)\n",
        "\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('italian'))\n",
        "\n",
        "    # Generazione della word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words).generate(text)\n",
        "    print(\"caricamento wordcloud completato\")\n",
        "\n",
        "    # Ottieni i dati degli autori da MongoDB\n",
        "    authors_data = collection.distinct(\"author\")\n",
        "    # Estrae i nomi dei giornalisti\n",
        "    journalist_names = extract_journalist_names(authors_data)\n",
        "    # Conta i nomi dei giornalisti\n",
        "    all_names = [name for sublist in journalist_names for name in sublist]\n",
        "    name_counts = Counter(all_names)\n",
        "\n",
        "    return collection, publish_date_counts, wordcloud, name_counts\n",
        "\n",
        "# Caricamento dei dati\n",
        "collection, publish_date_counts, wordcloud, name_counts = load_data()\n",
        "\n",
        "\n",
        "\n",
        "@st.cache_resource\n",
        "def load_embedding_model():\n",
        "    print(\"START LOAD EMBEDDING MODEL\")\n",
        "    embedding_model = SentenceTransformer(\"nickprock/sentence-bert-base-italian-xxl-uncased\", device='cuda')\n",
        "    return embedding_model\n",
        "\n",
        "embedding_model = load_embedding_model()\n",
        "\n",
        "\n",
        "\n",
        "def get_embedding(text: str) -> list[float]:\n",
        "    if not text.strip():\n",
        "        print(\"Attempted to get embedding for empty text.\")\n",
        "        return []\n",
        "\n",
        "    embedding = embedding_model.encode(text, device='cuda')\n",
        "\n",
        "    return embedding.tolist()\n",
        "\n",
        "\n",
        "def vector_search(user_query, collection):\n",
        "    \"\"\"\n",
        "    Perform a vector search in the MongoDB collection based on the user query.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string.\n",
        "    collection (MongoCollection): The MongoDB collection to search.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of matching documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate embedding for the user query\n",
        "    query_embedding = get_embedding(user_query)\n",
        "\n",
        "    if query_embedding is None:\n",
        "        return \"Invalid query or embedding generation failed.\"\n",
        "\n",
        "    # Define the vector search pipeline\n",
        "    pipeline = [\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": \"vector_index\",\n",
        "                \"queryVector\": query_embedding,\n",
        "                \"path\": \"embedding\",\n",
        "                \"numCandidates\": 250,  # Number of candidate matches to consider\n",
        "                \"limit\": 15,  # Return top 10 matches\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"$sort\": {\"publish_date\": -1}  # Sort by publish_date in descending order\n",
        "        },\n",
        "        {\n",
        "            \"$limit\": 15  # Limit to the top 10 results after sorting\n",
        "        },\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"_id\": 0,  # Exclude the _id field\n",
        "                \"title\": 1,  # Include the title field\n",
        "                \"text\": 1,  # Include the plot field\n",
        "                \"summary\": 1,\n",
        "                \"url\":1,\n",
        "                \"publish_date\": 1,\n",
        "                \"score\": {\"$meta\": \"vectorSearchScore\"},  # Include the search score\n",
        "            }\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Execute the search\n",
        "    results = collection.aggregate(pipeline)\n",
        "    return list(results)\n",
        "\n",
        "def response_generator(results_cleaned):\n",
        "    response = results_cleaned\n",
        "    for word in response.split():\n",
        "        yield word + \" \"\n",
        "        time.sleep(0.05)\n",
        "\n",
        "\n",
        "def get_search_result(query, collection):\n",
        "\n",
        "    get_knowledge = vector_search(query, collection)\n",
        "\n",
        "    search_result = \"\"\n",
        "    for result in get_knowledge:\n",
        "        url = result.get('url', 'N/A')\n",
        "\n",
        "        # Rimuovi il prefisso 'https://'\n",
        "        url = url.replace(\"https://\", \"\")\n",
        "\n",
        "        # Rimuovi 'www.' se presente\n",
        "        url = url.replace(\"www.\", \"\")\n",
        "\n",
        "        # Prendi solo la parte prima del primo '/'\n",
        "        site_name = url.split('/')[0]\n",
        "\n",
        "\n",
        "        search_result += f\"Titolo: {result.get('title', 'N/A')}, Summary: {result.get('summary','N/A')} Testo: {result.get('text', 'N/A')}, Fonte: {site_name}\\n\"\n",
        "\n",
        "    return search_result\n",
        "\n",
        "\n",
        "\n",
        "# Funzione per contare le istanze di un tipo di sentiment\n",
        "def conta_sentiment(sentiment):\n",
        "        global contatori_sentiment\n",
        "        if sentiment in contatori_sentiment:\n",
        "            contatori_sentiment[sentiment] += 1\n",
        "\n",
        "# Funzione per cercare una parola nei campi keywords e title\n",
        "def cerca_parola(document):\n",
        "        global parola_da_cercare\n",
        "        title = document.get('title', '')\n",
        "        if isinstance(title, str) and parola_da_cercare in title:\n",
        "            conta_sentiment(document.get('emotion'))\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer():\n",
        "    print(\"START LOAD MODEL\")\n",
        "    access_token = \"\"\n",
        "    login(token=access_token)\n",
        "    # Configurazione per quantizzazione a 8 bit\n",
        "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "    # Caricare il tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA\")\n",
        "\n",
        "    # Caricare e quantizzare il modello a 8 bit\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA\",\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=quantization_config\n",
        "    )\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model_and_tokenizer()\n",
        "\n",
        "st.title(\"ANITA FACT-CHECKER\")\n",
        "\n",
        "# Creare una barra laterale per la navigazione tra le pagine\n",
        "page = st.sidebar.radio(\"Seleziona una Pagina\", [\"Home\",\"Fact-Checker\" ,\"Q&A\", \"Chat\"])\n",
        "\n",
        "######################################################ANALYTICS#################################################################\n",
        "\n",
        "# Data Analytics\n",
        "if page == \"Home\":\n",
        "    st.header(\"Benvenuto in ANITA Fact-Checker!\")\n",
        "    # Schermata superiore\n",
        "    st.markdown(\"\"\"\n",
        "    <div style='background-color: rgba(240, 242, 246, 0.8); color: black; padding: 10px; border-radius: 5px;'>\n",
        "        <div>\n",
        "            Il seguente progetto sviluppa un sistema avanzato di Question&Answering (Q&A) utilizzando Large Language Models (LLM) e la tecnica Retrieval Augmented Generation (RAG). Questo permette agli LLM di accedere a informazioni esterne e generare risposte contestuali. L'obiettivo è creare un sistema Q&A che fornisca report con analisi dei dati e risposte rilevanti agli utenti. Il principale caso d'uso è il fact-checking, utilizzando articoli giornalistici per contrastare la disinformazione. Si noti che è possibile navigare nelle seguenti pagine:\n",
        "        </div>\n",
        "        <ul>\n",
        "            <li>Home: Visualizzazione di Grafici e Analytics varie per la comprensione del DataSet</li>\n",
        "            <li>FactChecker: Possibilità di effettuare un check di notizie dubbie</li>\n",
        "            <li>Q&A: Possibilità di fare domande di varia natura sugli ultimi argomenti</li>\n",
        "            <li>ChatBot: Possibilità di chattare con ANITA su vari argomenti</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Linea di separazione estetica\n",
        "    st.markdown(\"<hr style='border:2px solid white'>\", unsafe_allow_html=True)\n",
        "   # Numero di articoli con titoli unici\n",
        "    st.subheader(\"Conteggio Articoli nel Dataset\")\n",
        "    unique_titles_count = collection.aggregate([\n",
        "        {\"$group\": {\"_id\": \"$title\"}},\n",
        "        {\"$count\": \"unique_titles\"}\n",
        "    ])\n",
        "\n",
        "    unique_titles_count = list(unique_titles_count)\n",
        "    if unique_titles_count:\n",
        "        st.write(f\"Numero di Articoli nel DataSet: {unique_titles_count[0]['unique_titles']}\")\n",
        "    else:\n",
        "        st.write(\"Nessun articolo trovato.\")\n",
        "\n",
        "    # Distribuzione delle date di pubblicazione\n",
        "    st.subheader(\"Distribuzione delle Date di Pubblicazione\")\n",
        "    st.bar_chart(publish_date_counts)\n",
        "\n",
        "    # Word Cloud dei Titoli\n",
        "    st.subheader(\"Word Cloud dei Titoli\")\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    st.pyplot(plt)\n",
        "    # Funzione per estrarre il dominio dall'URL\n",
        "    def extract_domain(url):\n",
        "        match = re.search(r'www\\.(.*?)\\.(it|com)', url)\n",
        "        return match.group(1) if match else None\n",
        "    # Distribuzione per Testata Giornalistica\n",
        "    st.subheader(\"Distribuzione Articoli per Testata Giornalistica\")\n",
        "    title_counts = collection.aggregate([\n",
        "        {\"$group\": {\"_id\": {\"url\": \"$url\", \"title\": \"$title\"}}},\n",
        "        {\"$group\": {\"_id\": \"$_id.url\", \"count\": {\"$sum\": 1}}},\n",
        "        {\"$match\": {\"_id\": {\"$ne\": None}}},\n",
        "        {\"$sort\": {\"count\": -1}}\n",
        "    ])\n",
        "    title_counts = list(title_counts)\n",
        "    title_counts_df = pd.DataFrame(title_counts)\n",
        "    if not title_counts_df.empty:\n",
        "        # Estrazione del dominio\n",
        "        title_counts_df['_id'] = title_counts_df['_id'].apply(extract_domain)\n",
        "        title_counts_df = title_counts_df.dropna(subset=['_id'])\n",
        "        title_counts_df = title_counts_df.groupby('_id')['count'].sum().reset_index()\n",
        "        title_counts_df = title_counts_df.rename(columns={\"_id\": \"Testata Giornalistica\", \"count\": \"Numero Articoli\"})\n",
        "        st.bar_chart(title_counts_df.set_index(\"Testata Giornalistica\"))\n",
        "    else:\n",
        "        st.write(\"Nessuna Articolo per Testata Giornalistica trovato.\")\n",
        "\n",
        "\n",
        "    # Numero di giornalisti che han scritto di più\n",
        "\n",
        "    # Prepara i dati per il grafico\n",
        "    df = pd.DataFrame(name_counts.items(), columns=[\"Journalist\", \"Count\"])\n",
        "    # Sort DataFrame by \"Count\" column in descending order\n",
        "    df = df.sort_values(by=\"Count\", ascending=False)\n",
        "    # Take the first 30 rows\n",
        "    df = df.head(30)\n",
        "    # Visualizzazione con Streamlit\n",
        "    st.subheader(\"Giornalisti che hanno scritto di più\")\n",
        "    fig = px.bar(df, x=\"Journalist\", y=\"Count\", labels={\"Journalist\": \"Giornalista\", \"Count\": \"Conteggio\"})\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    if df.empty:\n",
        "        st.write(\"Nessun articolo trovato.\")\n",
        "\n",
        "    # Parola Chiave per Emotion\n",
        "    st.subheader(\"Emotion in base alle Parole Chiave\")\n",
        "    parola_da_cercare = st.text_input(\"Inserisci una parola chiave: \")\n",
        "    if parola_da_cercare:\n",
        "\n",
        "        # La pipeline di aggregazione\n",
        "        pipeline = [\n",
        "            # Filtro per i documenti che contengono la parola scelta nel testo\n",
        "            {\"$match\": {\"text\": {\"$regex\": parola_da_cercare, \"$options\": \"i\"}}},\n",
        "            # Eliminazione dei duplicati in base al titolo\n",
        "            {\"$group\": {\n",
        "                \"_id\": \"$title\",\n",
        "                \"text\": {\"$first\": \"$text\"},\n",
        "                \"emotion\": {\"$first\": \"$emotion\"}\n",
        "            }},\n",
        "            # Contare le emozioni\n",
        "            {\"$group\": {\n",
        "                \"_id\": \"$emotion\",\n",
        "                \"count\": {\"$sum\": 1}\n",
        "            }}\n",
        "        ]\n",
        "\n",
        "        # Esegui la pipeline di aggregazione\n",
        "        result = list(collection.aggregate(pipeline))\n",
        "\n",
        "        # Mappa delle emozioni in italiano\n",
        "        emotion_map = {\n",
        "            'joy': 'Felicità',\n",
        "            'anger': 'Rabbia',\n",
        "            'fear': 'Paura',\n",
        "            'sadness': 'Tristezza'\n",
        "        }\n",
        "\n",
        "        # Convertire gli ID delle emozioni nel nome leggibile\n",
        "        emotion_counts = {emotion_map[doc['_id']]: doc['count'] for doc in result}\n",
        "\n",
        "        #st.write(emotion_counts)\n",
        "        st.bar_chart(emotion_counts)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################\n",
        "\n",
        "#Q&A Page\n",
        "elif page == \"Q&A\":\n",
        "    st.header(\"Question & Answer\")\n",
        "\n",
        "    state = st.session_state\n",
        "\n",
        "    if 'text_received' not in state:\n",
        "        state.text_received = []\n",
        "\n",
        "    query = st.text_input(\"Inserisci Domanda: \")\n",
        "\n",
        "    if query:\n",
        "        # Query per Domanda\n",
        "        source_information = get_search_result(query, collection)\n",
        "        combined_information = f\"Domanda: {query}\\nContinuare a rispondere alla domanda in modo sintetico prestando attenzione anche ai risultati della ricerca.:\\n{source_information}.\"\n",
        "\n",
        "        sys = \"Sei un assistente AI specializzato nel fact-checking in lingua Italiana di nome LLaMAntino-3 ANITA \" \\\n",
        "            \"(Advanced Natural-based interaction for the ITAlian language).\" \\\n",
        "            \" Rispondi nella lingua usata in modo chiaro, semplice ed esaustivo in base ai risultati delle ricerche, considerando che sei aggiornato fino all' 13 giugno 2024\" \\\n",
        "            \"Rispondi solamente con la risposta, senza ripetere la domanda.\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": sys},\n",
        "            {\"role\": \"user\", \"content\": combined_information}\n",
        "        ]\n",
        "\n",
        "\n",
        "        #Risposta\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "        for k,v in inputs.items():\n",
        "            inputs[k] = v.cuda()\n",
        "        outputs = model.generate(**inputs, max_new_tokens=300, do_sample=True, top_p=0.9, temperature=0.6)\n",
        "\n",
        "        results = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # `skip_special_tokens` to remove tokens like <eos>\n",
        "        print(results)\n",
        "        # Pulizia del risultato per mantenere solo la parte dopo \".assistant\"\n",
        "        if \".assistant\" in results:\n",
        "            results_cleaned = results.split('.assistant')[-1].strip()\n",
        "        else:\n",
        "            results_cleaned = results\n",
        "\n",
        "        st.write(results_cleaned)\n",
        "\n",
        "    else:\n",
        "        st.write(\"Inserire una domanda per ottenere una risposta.\")\n",
        "\n",
        "\n",
        "#Fact-Cheker Page\n",
        "if page == \"Fact-Checker\":\n",
        "    st.header(\"Fact Checker\")\n",
        "\n",
        "\n",
        "    query = st.text_input(\"Inserisci Notizia: \")\n",
        "\n",
        "    if query:\n",
        "        # Query per Domanda\n",
        "        source_information = get_search_result(query, collection)\n",
        "        combined_information = f\"Notizia: {query}\\nContinuare a rispondere alla domanda in modo sintetico prestando attenzione anche ai risultati della ricerca.:\\n{source_information}.\"\n",
        "\n",
        "        sys = \"Sei un assistente AI specializzato nel fact-checking in lingua Italiana di nome LLaMAntino-3 ANITA \" \\\n",
        "            \"(Advanced Natural-based interaction for the ITAlian language).\" \\\n",
        "            \" Rispondi nella lingua usata in modo da far comprendere se la notizia è vera o falsa, considerando che sei aggiornato fino all' 13 giugno 2024.\" \\\n",
        "            \"Rispondi solamente con la risposta, senza ripetere la domanda.\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": sys},\n",
        "            {\"role\": \"user\", \"content\": combined_information}\n",
        "        ]\n",
        "\n",
        "\n",
        "        #Risposta\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "        for k,v in inputs.items():\n",
        "            inputs[k] = v.cuda()\n",
        "        outputs = model.generate(**inputs, max_new_tokens=300, do_sample=True, top_p=0.9, temperature=0.6)\n",
        "\n",
        "        results = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # `skip_special_tokens` to remove tokens like <eos>\n",
        "\n",
        "        # Pulizia del risultato per mantenere solo la parte dopo \".assistant\"\n",
        "        if \".assistant\" in results:\n",
        "            results_cleaned = results.split('.assistant')[-1].strip()\n",
        "        else:\n",
        "            results_cleaned = results\n",
        "\n",
        "        st.write(results_cleaned)\n",
        "    else:\n",
        "        st.write(\"Inserire un articolo per ottenere una risposta.\")\n",
        "\n",
        "#ChatBot Page\n",
        "if page == \"Chat\":\n",
        "        st.title(\"Inizia a chattare!\")\n",
        "\n",
        "\n",
        "        if st.button(\"🗑️ Clear Chat\"):\n",
        "          st.session_state.messages = [msg for msg in st.session_state.messages if msg.get('role') == 'system']\n",
        "          st.session_state.coda_query = \"\"\n",
        "          st.rerun()\n",
        "\n",
        "        # Initialize chat history\n",
        "        if \"messages\" not in st.session_state:\n",
        "            sys = \"Sei un assistente AI specializzato nel fact-checking in lingua Italiana di nome LLaMAntino-3 ANITA \" \\\n",
        "            \"(Advanced Natural-based interaction for the ITAlian language).\" \\\n",
        "            \"Rispondi nella lingua usata in modo chiaro, semplice ed esaustivo tenendo conto anche dei risultati delle ricerche, considerando che sei aggiornato fino al 13 giugno 2024.\" \\\n",
        "            \"Rispondi solamente con la risposta, senza ripetere la domanda, cercando di dare nua spiegazione esaustiva\"\n",
        "\n",
        "            st.session_state.messages = [{\"role\": \"system\", \"content\": sys}]\n",
        "            st.session_state.coda_query = \"\"  # Inizializza coda_query nella sessione\n",
        "\n",
        "\n",
        "        # Display chat messages from history on app rerun\n",
        "        for message in st.session_state.messages:\n",
        "          if message.get('role') != 'system':\n",
        "            with st.chat_message(message[\"role\"]):\n",
        "                st.markdown(message[\"content\"])\n",
        "\n",
        "        # Accept user input\n",
        "        if query := st.chat_input(\"What is up?\"):\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
        "            st.session_state.coda_query += \" \" + query\n",
        "            # Display user message in chat message container\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(query)\n",
        "\n",
        "            #prompt è la domanda\n",
        "            # Display assistant response in chat message container\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                source_information = get_search_result(st.session_state.coda_query, collection)\n",
        "                print(st.session_state.coda_query)\n",
        "                combined_information = f\"Notizia: {query}\\nContinuare a rispondere alla domanda in modo sintetico prestando attenzione anche ai risultati della ricerca.:\\n{source_information}.\"\n",
        "\n",
        "                #st.session_state.messages.append(   {\"role\": \"user\", \"content\": combined_information})\n",
        "\n",
        "                #Risposta\n",
        "                prompt = tokenizer.apply_chat_template(st.session_state.messages + [{\"role\": \"user\", \"content\": combined_information}], tokenize=False, add_generation_prompt=True)\n",
        "                inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "                for k,v in inputs.items():\n",
        "                    inputs[k] = v.cuda()\n",
        "                outputs = model.generate(**inputs, max_new_tokens=300, do_sample=True, top_p=0.9, temperature=0.8)\n",
        "\n",
        "                results = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # `skip_special_tokens` to remove tokens like <eos>\n",
        "\n",
        "                # Pulizia del risultato per mantenere solo la parte dopo \".assistant\"\n",
        "                if \".assistant\" in results:\n",
        "                    results_cleaned = results.split('.assistant')[-1].strip()\n",
        "                else:\n",
        "                    results_cleaned = results\n",
        "\n",
        "                response = st.write_stream(response_generator(results_cleaned))\n",
        "                # Add assistant response to chat history\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UigEody7xQXT",
        "outputId": "1aa38c7f-fc65-47d8-8f3d-7517f4fdce16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.82.226.246\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGgfDPySaaol",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bd9ce3-6e19-4776-c293-02f6f2846bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.82.226.246:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.18s\n",
            "your url is: https://young-bears-shave.loca.lt\n",
            "2024-06-16 08:05:58.368673: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-16 08:05:58.368752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-16 08:05:58.486550: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-16 08:05:58.733163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-16 08:06:00.306065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Pinged your deployment. You successfully connected to MongoDB!\n",
            "START LOAD DATA\n",
            "caricamento articles completato\n",
            "caricamento publish date completato\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "caricamento wordcloud completato\n",
            "START LOAD EMBEDDING MODEL\n",
            "modules.json: 100% 229/229 [00:00<00:00, 1.76MB/s]\n",
            "config_sentence_transformers.json: 100% 118/118 [00:00<00:00, 903kB/s]\n",
            "README.md: 100% 4.15k/4.15k [00:00<00:00, 22.8MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 423kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 641/641 [00:00<00:00, 4.87MB/s]\n",
            "model.safetensors: 100% 443M/443M [00:05<00:00, 84.2MB/s]\n",
            "tokenizer_config.json: 100% 436/436 [00:00<00:00, 3.11MB/s]\n",
            "vocab.txt: 100% 243k/243k [00:00<00:00, 1.79MB/s]\n",
            "tokenizer.json: 100% 732k/732k [00:00<00:00, 2.91MB/s]\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 698kB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.51MB/s]\n",
            "START LOAD MODEL\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "tokenizer_config.json: 100% 51.0k/51.0k [00:00<00:00, 128MB/s]\n",
            "tokenizer.json: 100% 9.08M/9.08M [00:00<00:00, 19.3MB/s]\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 2.16MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "config.json: 100% 654/654 [00:00<00:00, 4.61MB/s]\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 81.9MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 21.0M/4.98G [00:00<00:29, 168MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 52.4M/4.98G [00:00<00:22, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 83.9M/4.98G [00:00<00:21, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 115M/4.98G [00:00<00:22, 219MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 147M/4.98G [00:00<00:22, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 178M/4.98G [00:00<00:22, 212MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 210M/4.98G [00:00<00:22, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 241M/4.98G [00:01<00:21, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 273M/4.98G [00:01<00:21, 224MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6% 304M/4.98G [00:01<00:20, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 336M/4.98G [00:01<00:20, 229MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 367M/4.98G [00:01<00:21, 211MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 398M/4.98G [00:01<00:22, 203MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 419M/4.98G [00:01<00:22, 203MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 451M/4.98G [00:02<00:21, 207MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 472M/4.98G [00:02<00:22, 204MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 493M/4.98G [00:04<02:09, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 524M/4.98G [00:04<01:30, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 545M/4.98G [00:04<01:12, 60.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 577M/4.98G [00:04<00:55, 79.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 598M/4.98G [00:04<00:46, 94.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 619M/4.98G [00:04<00:40, 108MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 640M/4.98G [00:05<00:35, 123MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 671M/4.98G [00:05<00:29, 148MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 703M/4.98G [00:05<00:25, 167MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 734M/4.98G [00:05<00:23, 180MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 765M/4.98G [00:05<00:21, 196MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 797M/4.98G [00:05<00:20, 202MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 828M/4.98G [00:05<00:19, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 860M/4.98G [00:06<00:19, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 891M/4.98G [00:06<00:18, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 923M/4.98G [00:06<00:19, 213MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 954M/4.98G [00:06<00:19, 211MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 986M/4.98G [00:06<00:18, 212MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 1.02G/4.98G [00:06<00:18, 211MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.05G/4.98G [00:10<02:31, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.08G/4.98G [00:10<01:51, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.11G/4.98G [00:10<01:21, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.14G/4.98G [00:10<01:02, 61.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.16G/4.98G [00:11<00:52, 72.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.18G/4.98G [00:11<00:43, 86.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.22G/4.98G [00:11<00:34, 109MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.25G/4.98G [00:11<00:28, 131MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.28G/4.98G [00:11<00:24, 150MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.31G/4.98G [00:11<00:22, 167MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.34G/4.98G [00:11<00:19, 182MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.37G/4.98G [00:11<00:18, 190MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.41G/4.98G [00:12<00:17, 202MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.44G/4.98G [00:12<00:16, 212MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.47G/4.98G [00:12<00:15, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.50G/4.98G [00:12<00:16, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.53G/4.98G [00:12<00:16, 205MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.56G/4.98G [00:12<00:15, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.59G/4.98G [00:12<00:15, 219MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.63G/4.98G [00:13<00:14, 227MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.66G/4.98G [00:13<00:15, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.69G/4.98G [00:13<00:15, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.72G/4.98G [00:13<00:15, 210MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.75G/4.98G [00:13<00:15, 206MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.77G/4.98G [00:13<00:15, 206MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.79G/4.98G [00:13<00:15, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.82G/4.98G [00:14<00:15, 206MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.86G/4.98G [00:14<00:14, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:14<00:13, 222MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.92G/4.98G [00:14<00:13, 226MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.95G/4.98G [00:14<00:13, 229MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.98G/4.98G [00:14<00:13, 215MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 2.01G/4.98G [00:14<00:15, 195MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.03G/4.98G [00:15<00:15, 195MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.06G/4.98G [00:15<00:14, 197MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.08G/4.98G [00:15<00:15, 193MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.10G/4.98G [00:15<00:18, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.12G/4.98G [00:15<00:16, 169MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.14G/4.98G [00:15<00:16, 171MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.16G/4.98G [00:15<00:15, 179MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.18G/4.98G [00:15<00:15, 178MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.20G/4.98G [00:16<00:15, 178MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.22G/4.98G [00:16<00:15, 177MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.24G/4.98G [00:16<00:15, 176MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.26G/4.98G [00:16<00:15, 174MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.29G/4.98G [00:18<01:29, 30.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.31G/4.98G [00:18<01:15, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.33G/4.98G [00:18<00:57, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.36G/4.98G [00:19<00:39, 66.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.39G/4.98G [00:19<00:29, 88.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.42G/4.98G [00:19<00:23, 110MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.45G/4.98G [00:19<00:19, 132MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.49G/4.98G [00:19<00:16, 150MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.51G/4.98G [00:19<00:15, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.53G/4.98G [00:19<00:14, 170MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.55G/4.98G [00:19<00:13, 177MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.57G/4.98G [00:20<00:13, 183MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.60G/4.98G [00:20<00:12, 191MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.63G/4.98G [00:20<00:11, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.66G/4.98G [00:20<00:11, 206MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.69G/4.98G [00:20<00:10, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.73G/4.98G [00:21<00:15, 146MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.76G/4.98G [00:21<00:13, 164MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.79G/4.98G [00:21<00:11, 183MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.81G/4.98G [00:21<00:11, 186MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.84G/4.98G [00:21<00:10, 197MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.87G/4.98G [00:21<00:10, 203MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.90G/4.98G [00:21<00:09, 210MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.94G/4.98G [00:21<00:09, 213MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.97G/4.98G [00:22<00:09, 218MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 3.00G/4.98G [00:22<00:08, 220MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.03G/4.98G [00:22<00:19, 99.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.05G/4.98G [00:23<00:17, 109MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.08G/4.98G [00:23<00:14, 134MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.10G/4.98G [00:23<00:12, 144MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.14G/4.98G [00:23<00:11, 163MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.17G/4.98G [00:23<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.20G/4.98G [00:23<00:09, 198MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.23G/4.98G [00:25<00:30, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.25G/4.98G [00:25<00:25, 68.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.28G/4.98G [00:25<00:18, 89.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.31G/4.98G [00:25<00:14, 112MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.34G/4.98G [00:25<00:12, 132MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.38G/4.98G [00:25<00:10, 151MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.41G/4.98G [00:25<00:09, 168MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.44G/4.98G [00:26<00:08, 182MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.47G/4.98G [00:26<00:07, 198MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.50G/4.98G [00:26<00:07, 208MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.53G/4.98G [00:26<00:06, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.57G/4.98G [00:26<00:06, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.60G/4.98G [00:26<00:06, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 3.63G/4.98G [00:26<00:05, 229MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.66G/4.98G [00:27<00:05, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.69G/4.98G [00:27<00:05, 239MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.72G/4.98G [00:27<00:05, 240MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.75G/4.98G [00:27<00:05, 242MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.79G/4.98G [00:27<00:04, 244MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.82G/4.98G [00:27<00:05, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.85G/4.98G [00:27<00:05, 207MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.88G/4.98G [00:28<00:05, 198MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.90G/4.98G [00:28<00:05, 195MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.92G/4.98G [00:28<00:09, 110MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.94G/4.98G [00:28<00:08, 123MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.96G/4.98G [00:28<00:07, 136MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.98G/4.98G [00:28<00:06, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 4.01G/4.98G [00:29<00:06, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.03G/4.98G [00:29<00:05, 163MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.05G/4.98G [00:29<00:05, 173MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.08G/4.98G [00:29<00:05, 176MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.10G/4.98G [00:29<00:04, 178MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.13G/4.98G [00:29<00:04, 188MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.15G/4.98G [00:29<00:04, 189MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.17G/4.98G [00:29<00:04, 185MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.19G/4.98G [00:30<00:04, 186MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.22G/4.98G [00:30<00:04, 172MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.24G/4.98G [00:30<00:04, 181MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.26G/4.98G [00:30<00:04, 179MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.28G/4.98G [00:30<00:03, 185MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.30G/4.98G [00:30<00:03, 186MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.33G/4.98G [00:30<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.35G/4.98G [00:30<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.38G/4.98G [00:31<00:02, 217MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.41G/4.98G [00:31<00:02, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.45G/4.98G [00:31<00:02, 240MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.48G/4.98G [00:31<00:02, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.51G/4.98G [00:31<00:02, 227MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.54G/4.98G [00:31<00:01, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.57G/4.98G [00:31<00:01, 219MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.60G/4.98G [00:31<00:01, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.63G/4.98G [00:32<00:01, 226MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.67G/4.98G [00:32<00:01, 232MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.70G/4.98G [00:32<00:01, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.73G/4.98G [00:32<00:01, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.76G/4.98G [00:32<00:00, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.79G/4.98G [00:32<00:00, 226MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.82G/4.98G [00:32<00:00, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.85G/4.98G [00:33<00:00, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.89G/4.98G [00:34<00:01, 57.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.92G/4.98G [00:34<00:00, 74.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.95G/4.98G [00:34<00:00, 93.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:35<00:00, 142MB/s] \n",
            "Downloading shards:  25% 1/4 [00:35<01:46, 35.42s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 31.5M/5.00G [00:00<00:19, 251MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 62.9M/5.00G [00:00<00:20, 235MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 94.4M/5.00G [00:00<00:20, 237MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 126M/5.00G [00:00<00:20, 242MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 157M/5.00G [00:00<00:20, 237MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 189M/5.00G [00:00<00:20, 230MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 220M/5.00G [00:00<00:21, 226MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 252M/5.00G [00:01<00:20, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 283M/5.00G [00:01<00:20, 225MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 315M/5.00G [00:01<00:20, 227MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 346M/5.00G [00:01<00:20, 228MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 377M/5.00G [00:01<00:20, 227MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 409M/5.00G [00:01<00:19, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 440M/5.00G [00:01<00:19, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 472M/5.00G [00:02<00:19, 231MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 503M/5.00G [00:02<00:19, 231MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 535M/5.00G [00:02<00:19, 231MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 566M/5.00G [00:02<00:19, 232MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 598M/5.00G [00:02<00:18, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 629M/5.00G [00:02<00:18, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 661M/5.00G [00:02<00:18, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 692M/5.00G [00:02<00:18, 237MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 724M/5.00G [00:03<00:17, 239MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 755M/5.00G [00:03<00:17, 243MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 786M/5.00G [00:03<00:17, 235MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 818M/5.00G [00:03<00:17, 242MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 849M/5.00G [00:03<00:16, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 881M/5.00G [00:03<00:16, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 912M/5.00G [00:03<00:17, 235MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 944M/5.00G [00:04<00:17, 232MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 975M/5.00G [00:04<00:17, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 1.01G/5.00G [00:04<00:17, 228MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.04G/5.00G [00:04<00:19, 202MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.06G/5.00G [00:04<00:21, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.08G/5.00G [00:04<00:22, 171MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.11G/5.00G [00:04<00:21, 185MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.13G/5.00G [00:05<00:21, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.15G/5.00G [00:05<00:27, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.17G/5.00G [00:05<00:27, 141MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.20G/5.00G [00:05<00:28, 132MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.22G/5.00G [00:05<00:28, 132MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.24G/5.00G [00:05<00:27, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.26G/5.00G [00:06<00:31, 118MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.28G/5.00G [00:06<00:31, 117MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.30G/5.00G [00:06<00:36, 102MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.32G/5.00G [00:06<00:37, 97.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.34G/5.00G [00:07<00:34, 107MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.36G/5.00G [00:07<00:32, 113MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.38G/5.00G [00:07<00:32, 112MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.41G/5.00G [00:07<00:31, 115MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.43G/5.00G [00:07<00:29, 123MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.45G/5.00G [00:07<00:30, 116MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.47G/5.00G [00:08<00:30, 118MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.49G/5.00G [00:10<02:04, 28.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.50G/5.00G [00:12<03:38, 16.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.53G/5.00G [00:12<02:09, 26.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.55G/5.00G [00:12<01:36, 35.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.57G/5.00G [00:12<01:15, 45.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.59G/5.00G [00:12<01:00, 56.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.61G/5.00G [00:12<00:48, 70.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.64G/5.00G [00:12<00:39, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.66G/5.00G [00:13<00:34, 96.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.68G/5.00G [00:13<00:29, 112MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.71G/5.00G [00:13<00:23, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.74G/5.00G [00:13<00:21, 153MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.76G/5.00G [00:13<00:21, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.78G/5.00G [00:13<00:20, 154MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.80G/5.00G [00:13<00:19, 161MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.82G/5.00G [00:13<00:19, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.85G/5.00G [00:14<00:18, 168MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.87G/5.00G [00:15<00:55, 56.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.89G/5.00G [00:15<00:45, 69.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.91G/5.00G [00:15<00:36, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.93G/5.00G [00:15<00:30, 99.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.95G/5.00G [00:15<00:28, 108MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.97G/5.00G [00:15<00:25, 118MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.99G/5.00G [00:15<00:22, 131MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 2.01G/5.00G [00:15<00:20, 143MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 2.04G/5.00G [00:16<00:17, 169MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.08G/5.00G [00:16<00:15, 186MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.11G/5.00G [00:16<00:15, 192MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.13G/5.00G [00:16<00:16, 177MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.15G/5.00G [00:16<00:16, 177MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.17G/5.00G [00:16<00:16, 168MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.19G/5.00G [00:16<00:17, 165MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.21G/5.00G [00:17<00:15, 175MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.23G/5.00G [00:17<00:15, 179MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.26G/5.00G [00:17<00:14, 194MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.29G/5.00G [00:17<00:14, 188MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.31G/5.00G [00:17<00:15, 173MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.33G/5.00G [00:17<00:16, 167MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.35G/5.00G [00:17<00:15, 171MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.37G/5.00G [00:17<00:14, 176MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.39G/5.00G [00:20<01:29, 29.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.41G/5.00G [00:20<01:07, 38.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.43G/5.00G [00:20<00:51, 49.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.45G/5.00G [00:20<00:40, 63.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.47G/5.00G [00:20<00:33, 74.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.50G/5.00G [00:20<00:29, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.52G/5.00G [00:20<00:25, 98.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.54G/5.00G [00:21<00:22, 108MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.56G/5.00G [00:21<00:21, 115MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.58G/5.00G [00:21<00:20, 117MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.60G/5.00G [00:21<00:19, 122MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.62G/5.00G [00:21<00:18, 128MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.64G/5.00G [00:21<00:17, 131MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.66G/5.00G [00:22<00:17, 134MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.68G/5.00G [00:22<00:16, 139MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.71G/5.00G [00:22<00:15, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.73G/5.00G [00:22<00:14, 157MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.75G/5.00G [00:22<00:15, 146MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.77G/5.00G [00:22<00:15, 142MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.79G/5.00G [00:22<00:16, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.81G/5.00G [00:23<00:15, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.83G/5.00G [00:23<00:15, 137MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.85G/5.00G [00:23<00:14, 147MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.87G/5.00G [00:23<00:15, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.89G/5.00G [00:23<00:15, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.92G/5.00G [00:23<00:15, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.94G/5.00G [00:23<00:15, 136MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.96G/5.00G [00:24<00:14, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 2.98G/5.00G [00:26<01:18, 25.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 3.01G/5.00G [00:26<00:50, 39.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.04G/5.00G [00:26<00:34, 56.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:26<00:25, 75.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.09G/5.00G [00:27<00:22, 83.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.12G/5.00G [00:27<00:17, 106MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.15G/5.00G [00:27<00:15, 121MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.18G/5.00G [00:27<00:12, 144MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.20G/5.00G [00:27<00:12, 145MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.22G/5.00G [00:27<00:11, 151MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.24G/5.00G [00:27<00:11, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.26G/5.00G [00:27<00:11, 153MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.28G/5.00G [00:28<00:10, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.30G/5.00G [00:28<00:09, 173MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.32G/5.00G [00:28<00:09, 175MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.36G/5.00G [00:28<00:08, 196MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.38G/5.00G [00:28<00:09, 169MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.41G/5.00G [00:28<00:08, 185MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.43G/5.00G [00:28<00:08, 183MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.46G/5.00G [00:28<00:07, 201MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.48G/5.00G [00:29<00:08, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.50G/5.00G [00:29<00:08, 172MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.52G/5.00G [00:29<00:08, 166MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.54G/5.00G [00:29<00:08, 169MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.57G/5.00G [00:29<00:08, 174MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.59G/5.00G [00:29<00:07, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.61G/5.00G [00:29<00:07, 183MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.64G/5.00G [00:29<00:07, 194MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.67G/5.00G [00:30<00:06, 205MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.70G/5.00G [00:30<00:06, 202MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.72G/5.00G [00:30<00:07, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.74G/5.00G [00:30<00:07, 177MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.76G/5.00G [00:30<00:07, 173MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.79G/5.00G [00:30<00:06, 174MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.81G/5.00G [00:30<00:07, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.84G/5.00G [00:31<00:06, 184MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.87G/5.00G [00:31<00:06, 179MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.89G/5.00G [00:31<00:06, 161MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.92G/5.00G [00:31<00:06, 177MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.95G/5.00G [00:31<00:05, 193MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.97G/5.00G [00:34<00:35, 28.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80% 4.01G/5.00G [00:34<00:24, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.04G/5.00G [00:34<00:16, 56.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.07G/5.00G [00:34<00:12, 74.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.09G/5.00G [00:34<00:10, 84.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.11G/5.00G [00:35<00:09, 95.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.13G/5.00G [00:35<00:07, 109MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.15G/5.00G [00:35<00:06, 123MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.17G/5.00G [00:35<00:05, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.19G/5.00G [00:35<00:05, 153MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.22G/5.00G [00:35<00:04, 165MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.24G/5.00G [00:35<00:04, 176MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [00:35<00:04, 183MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.29G/5.00G [00:35<00:03, 202MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.32G/5.00G [00:36<00:03, 182MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.34G/5.00G [00:36<00:03, 183MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.36G/5.00G [00:36<00:03, 170MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.38G/5.00G [00:36<00:03, 154MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.40G/5.00G [00:40<00:34, 17.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.42G/5.00G [00:40<00:24, 23.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.46G/5.00G [00:40<00:15, 35.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.49G/5.00G [00:40<00:10, 50.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.51G/5.00G [00:41<00:07, 61.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.53G/5.00G [00:41<00:06, 72.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.55G/5.00G [00:41<00:05, 84.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:41<00:04, 99.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.59G/5.00G [00:41<00:03, 114MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.62G/5.00G [00:41<00:02, 140MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.65G/5.00G [00:41<00:02, 148MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.67G/5.00G [00:41<00:02, 155MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.70G/5.00G [00:42<00:01, 173MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.72G/5.00G [00:42<00:01, 175MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.74G/5.00G [00:42<00:01, 170MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.76G/5.00G [00:42<00:01, 159MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.79G/5.00G [00:42<00:01, 175MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.81G/5.00G [00:43<00:03, 55.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.83G/5.00G [00:44<00:03, 48.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.85G/5.00G [00:44<00:02, 61.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.88G/5.00G [00:44<00:01, 77.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.90G/5.00G [00:44<00:01, 92.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.92G/5.00G [00:44<00:00, 111MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  99% 4.95G/5.00G [00:44<00:00, 137MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:45<00:00, 111MB/s]\n",
            "Downloading shards:  50% 2/4 [01:20<01:22, 41.24s/it]\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 31.5M/4.92G [00:00<00:21, 223MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 62.9M/4.92G [00:00<00:24, 201MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 94.4M/4.92G [00:00<00:21, 220MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 126M/4.92G [00:00<00:21, 223MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 157M/4.92G [00:00<00:21, 223MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 189M/4.92G [00:00<00:21, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 220M/4.92G [00:00<00:21, 223MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 252M/4.92G [00:01<00:20, 222MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 283M/4.92G [00:01<00:20, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 315M/4.92G [00:01<00:20, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 346M/4.92G [00:01<00:19, 234MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 377M/4.92G [00:01<00:18, 242MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 409M/4.92G [00:01<00:19, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 440M/4.92G [00:01<00:19, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 472M/4.92G [00:02<00:19, 226MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 503M/4.92G [00:02<00:19, 231MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 535M/4.92G [00:02<00:21, 200MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 556M/4.92G [00:02<00:23, 187MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 577M/4.92G [00:02<00:25, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 598M/4.92G [00:02<00:27, 160MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 619M/4.92G [00:03<00:26, 162MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 640M/4.92G [00:03<00:31, 135MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 661M/4.92G [00:03<00:29, 144MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 682M/4.92G [00:03<00:28, 148MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 703M/4.92G [00:03<00:28, 147MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 724M/4.92G [00:03<00:29, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 744M/4.92G [00:03<00:31, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 765M/4.92G [00:04<00:30, 136MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 786M/4.92G [00:04<00:31, 132MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 807M/4.92G [00:04<00:29, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 828M/4.92G [00:04<00:28, 146MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 849M/4.92G [00:04<00:27, 146MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 870M/4.92G [00:04<00:27, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 891M/4.92G [00:05<00:30, 131MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 912M/4.92G [00:05<00:30, 131MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 933M/4.92G [00:05<00:30, 132MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 954M/4.92G [00:05<00:28, 137MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 975M/4.92G [00:05<00:28, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 996M/4.92G [00:05<00:25, 153MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 1.02G/4.92G [00:05<00:25, 155MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 1.04G/4.92G [00:06<00:26, 147MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.06G/4.92G [00:06<00:30, 127MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.08G/4.92G [00:06<00:29, 128MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.10G/4.92G [00:06<00:28, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.12G/4.92G [00:08<02:03, 30.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.13G/4.92G [00:09<02:57, 21.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.15G/4.92G [00:09<02:03, 30.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.17G/4.92G [00:09<01:29, 41.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.21G/4.92G [00:09<00:58, 63.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.24G/4.92G [00:10<00:41, 87.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.26G/4.92G [00:10<00:45, 81.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.29G/4.92G [00:10<00:34, 105MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.32G/4.92G [00:10<00:28, 128MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.35G/4.92G [00:10<00:23, 152MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.38G/4.92G [00:10<00:20, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.42G/4.92G [00:11<00:18, 185MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.45G/4.92G [00:11<00:17, 193MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.48G/4.92G [00:11<00:16, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.51G/4.92G [00:11<00:15, 215MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.54G/4.92G [00:11<00:15, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.57G/4.92G [00:11<00:14, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.60G/4.92G [00:11<00:14, 222MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.64G/4.92G [00:15<02:10, 25.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.67G/4.92G [00:15<01:33, 34.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.70G/4.92G [00:15<01:08, 46.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.73G/4.92G [00:16<00:51, 61.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.76G/4.92G [00:16<00:40, 77.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.79G/4.92G [00:16<00:32, 96.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.82G/4.92G [00:16<00:26, 117MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.86G/4.92G [00:16<00:22, 137MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.89G/4.92G [00:16<00:19, 157MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.92G/4.92G [00:16<00:17, 172MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.95G/4.92G [00:17<00:16, 185MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.98G/4.92G [00:17<00:15, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 2.01G/4.92G [00:17<00:14, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.04G/4.92G [00:17<00:13, 216MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.08G/4.92G [00:17<00:12, 227MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 2.11G/4.92G [00:17<00:12, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.14G/4.92G [00:17<00:12, 227MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.17G/4.92G [00:18<00:11, 230MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.20G/4.92G [00:18<00:13, 201MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.23G/4.92G [00:18<00:14, 181MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.25G/4.92G [00:18<00:15, 173MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.29G/4.92G [00:18<00:13, 191MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.32G/4.92G [00:18<00:12, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.34G/4.92G [00:19<00:13, 188MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.36G/4.92G [00:19<00:14, 181MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.38G/4.92G [00:19<00:13, 187MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.40G/4.92G [00:19<00:13, 189MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.42G/4.92G [00:19<00:12, 193MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 2.45G/4.92G [00:19<00:12, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.49G/4.92G [00:19<00:11, 211MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.52G/4.92G [00:19<00:11, 200MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.54G/4.92G [00:20<00:12, 196MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.56G/4.92G [00:20<00:12, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.59G/4.92G [00:20<00:11, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.61G/4.92G [00:20<00:11, 198MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.64G/4.92G [00:20<00:11, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.67G/4.92G [00:20<00:10, 212MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.71G/4.92G [00:20<00:10, 218MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.74G/4.92G [00:20<00:11, 196MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.76G/4.92G [00:21<00:11, 193MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.79G/4.92G [00:21<00:10, 198MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.81G/4.92G [00:23<01:12, 28.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.83G/4.92G [00:24<01:01, 33.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.85G/4.92G [00:24<00:50, 41.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.87G/4.92G [00:24<00:39, 51.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.89G/4.92G [00:24<00:31, 64.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.92G/4.92G [00:24<00:25, 79.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.94G/4.92G [00:25<00:22, 86.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.96G/4.92G [00:25<00:18, 104MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.99G/4.92G [00:25<00:14, 132MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 3.02G/4.92G [00:25<00:12, 157MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.05G/4.92G [00:25<00:10, 176MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.08G/4.92G [00:25<00:09, 187MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.11G/4.92G [00:25<00:09, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 3.15G/4.92G [00:25<00:08, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.18G/4.92G [00:26<00:08, 212MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.21G/4.92G [00:26<00:07, 218MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 3.24G/4.92G [00:26<00:07, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.27G/4.92G [00:26<00:07, 230MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.30G/4.92G [00:26<00:07, 230MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.33G/4.92G [00:26<00:06, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.37G/4.92G [00:26<00:06, 242MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 3.40G/4.92G [00:27<00:06, 244MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.43G/4.92G [00:27<00:06, 235MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.46G/4.92G [00:27<00:06, 231MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.49G/4.92G [00:27<00:05, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.52G/4.92G [00:27<00:05, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.55G/4.92G [00:27<00:05, 240MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.59G/4.92G [00:27<00:05, 234MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.62G/4.92G [00:28<00:08, 154MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.65G/4.92G [00:28<00:07, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.68G/4.92G [00:28<00:07, 173MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.71G/4.92G [00:28<00:06, 188MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.73G/4.92G [00:28<00:06, 191MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.76G/4.92G [00:28<00:05, 203MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.80G/4.92G [00:29<00:05, 214MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.83G/4.92G [00:29<00:04, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.86G/4.92G [00:29<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.89G/4.92G [00:29<00:04, 227MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.92G/4.92G [00:29<00:04, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.95G/4.92G [00:29<00:04, 240MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.98G/4.92G [00:29<00:03, 243MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.02G/4.92G [00:29<00:03, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.05G/4.92G [00:30<00:03, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.08G/4.92G [00:30<00:03, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.11G/4.92G [00:30<00:03, 243MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.14G/4.92G [00:30<00:03, 243MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.17G/4.92G [00:30<00:03, 229MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.20G/4.92G [00:30<00:03, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.24G/4.92G [00:30<00:03, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.27G/4.92G [00:31<00:02, 222MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.30G/4.92G [00:31<00:02, 226MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 4.33G/4.92G [00:31<00:02, 228MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.36G/4.92G [00:31<00:02, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.39G/4.92G [00:31<00:02, 234MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.42G/4.92G [00:31<00:02, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.46G/4.92G [00:31<00:01, 235MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:31<00:01, 242MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.52G/4.92G [00:32<00:01, 231MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.55G/4.92G [00:32<00:01, 222MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.58G/4.92G [00:32<00:01, 203MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.60G/4.92G [00:33<00:06, 49.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.62G/4.92G [00:34<00:04, 60.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.65G/4.92G [00:34<00:03, 73.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 4.67G/4.92G [00:34<00:02, 87.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 4.69G/4.92G [00:34<00:02, 103MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.71G/4.92G [00:34<00:01, 119MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.74G/4.92G [00:34<00:01, 145MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 4.77G/4.92G [00:34<00:00, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.80G/4.92G [00:34<00:00, 181MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.83G/4.92G [00:35<00:00, 190MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.87G/4.92G [00:35<00:00, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:35<00:00, 139MB/s]\n",
            "Downloading shards:  75% 3/4 [01:56<00:38, 38.69s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3% 31.5M/1.17G [00:00<00:04, 266MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   5% 62.9M/1.17G [00:00<00:04, 237MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   8% 94.4M/1.17G [00:00<00:04, 232MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  11% 126M/1.17G [00:00<00:04, 234MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 157M/1.17G [00:00<00:04, 235MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  16% 189M/1.17G [00:00<00:03, 246MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  19% 220M/1.17G [00:00<00:03, 247MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  22% 252M/1.17G [00:01<00:03, 243MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24% 283M/1.17G [00:01<00:03, 233MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27% 315M/1.17G [00:01<00:03, 230MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  30% 346M/1.17G [00:01<00:03, 231MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 377M/1.17G [00:01<00:03, 237MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35% 409M/1.17G [00:01<00:03, 234MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  38% 440M/1.17G [00:01<00:03, 230MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  40% 472M/1.17G [00:02<00:03, 227MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  43% 503M/1.17G [00:02<00:02, 236MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46% 535M/1.17G [00:02<00:02, 237MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  48% 566M/1.17G [00:02<00:02, 232MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  51% 598M/1.17G [00:02<00:02, 239MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  54% 629M/1.17G [00:02<00:02, 226MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57% 661M/1.17G [00:02<00:02, 224MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  59% 692M/1.17G [00:02<00:02, 225MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  62% 724M/1.17G [00:03<00:02, 170MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  65% 755M/1.17G [00:03<00:02, 183MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  67% 786M/1.17G [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70% 818M/1.17G [00:03<00:01, 201MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 849M/1.17G [00:03<00:01, 209MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75% 881M/1.17G [00:03<00:01, 213MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78% 912M/1.17G [00:04<00:01, 218MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  81% 944M/1.17G [00:04<00:00, 225MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83% 975M/1.17G [00:04<00:00, 219MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86% 1.01G/1.17G [00:04<00:00, 222MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  89% 1.04G/1.17G [00:04<00:00, 223MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92% 1.07G/1.17G [00:04<00:00, 224MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  94% 1.10G/1.17G [00:04<00:00, 226MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  97% 1.13G/1.17G [00:05<00:00, 223MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:05<00:00, 223MB/s]\n",
            "Downloading shards: 100% 4/4 [02:01<00:00, 30.46s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [01:20<00:00, 20.22s/it]\n",
            "generation_config.json: 100% 182/182 [00:00<00:00, 965kB/s]\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "system\n",
            "\n",
            "Sei un assistente AI specializzato nel fact-checking in lingua Italiana di nome LLaMAntino-3 ANITA (Advanced Natural-based interaction for the ITAlian language). Rispondi nella lingua usata in modo chiaro, semplice ed esaustivo in base ai risultati delle ricerche, considerando che sei aggiornato fino all' 13 giugno 2024Rispondi solamente con la risposta, senza ripetere la domanda.user\n",
            "\n",
            "Domanda: La torre di Pisa cadrà\n",
            "Continuare a rispondere alla domanda in modo sintetico prestando attenzione anche ai risultati della ricerca.:\n",
            "Titolo: Incidente Rosignano, auto travolge veicoli in coda: 3 morti e 6 feriti tra cui due bambini. Ipotesi malore all, Summary: Un incidente al casello di Rosignano, nell'autostrada Roma-Genova, ha portato alla morte di tre persone e alla chiusura di un tratto dell'A12. Dalle prime informazioni sulla dinamica... Testo: La struttura del casello ha subito danni molto gravi: è praticamente distrutta., Fonte: ilmattino.it\n",
            "Titolo: Torre di Pisa, nei bagni pubblici si paga solo con carta e bancomat. Consigliere regionale Fdi: “Inaccettabil…, Summary: La polemica di Diego Petrucci. “Scelta sbagliata dell’Opera primaziale, ci sono lunghe file: e se mancasse la connessione cosa farà chi ha necessità impellenti. Un salto nel tempo in stile Svezia, dove musei, parcheggi, biglietterie delle stazioni, e gli stessi servizi igienici, sono da tempo cashless: forse troppo avanti Testo: Pisa., Fonte: repubblica.it\n",
            "Titolo: Napoli, un altro choc sul lavoro: operaio in fin di vita, Summary: Una barra di ferro è caduta da una gru. E lo ha centrato in pieno, all?altezza della testa. È accaduto sabato scorso, nei pressi di un capannone di via Volpicelli, siamo a... Testo: Una barra di ferro è caduta da una gru., Fonte: ilmattino.it\n",
            "Titolo: Negoziati sul cessate il fuoco. Mediatori ottimisti: “Hamas pronta al sì”. E Israele si divide, Summary: I jihadisti sarebbero disponibili a un’intesa anche senza lo stop definitivo alla guerra. Ma manca la conferma. Netanyahu sotto pressione da destra e famiglie degli ostaggi Testo: L’architrave è solido e soddisfa entrambe le parti; ma è nei dettagli che il castello rischia di crollare., Fonte: repubblica.it\n",
            "Titolo: Maltempo, temporali fino a domani in Italia: a Milano allagamenti nella notte, Seveso a livello di allerta. Al, Summary: La bassa pressione che ha colpito l'Italia a partire da mercoledì 1°maggio è destinata a durare anche per le giornate di giovedì 2 maggio e venerdì 3 maggio.... Testo: All'alba, in piazza del Cavalletto in centro città, sono caduti alcuni pezzi di cornicione dalla facciata di un palazzo., Fonte: ilmattino.it\n",
            "Titolo: Venezia, cadono pezzi di cemento armato dal campanile di San Marco. La Procuratoria: “Non ci sono pericoli im…, Summary: Saranno avviati lavori di consolidamento Testo: Alcuni pezzi di cemento armato si sono staccati dalla cima del campanile di San Marco, a Venezia., Fonte: repubblica.it\n",
            "Titolo: Venezia, crollano pezzi di cemento armato dal campanile di San Marco: controlli immediati su cuspide e fondame, Summary: Paura a Venezia, dove alcuni pezzi di cemento armato sono caduti dalla cima del campanile di San Marco, non provocando però nessun ferito. Partiti subito i controlli sullo stato della cuspide... Testo: Campanile di San Marco, la storia di uno dei simboli di Venezia tra crolli e ricostruzioni Il crollo Alcuni pezzi di cemento armato si sono staccati dalla cima del campanile di San Marco, a Venezia., Fonte: ilmattino.it\n",
            "Titolo: Incendio a Copenaghen, in fiamme l'edificio della Borsa: crollata la celebre guglia e opere d'arte a rischio, Summary: Un incendio di vaste proporzioni nell'ex Borsa Valori di Copenaghen, risalente al XVII secolo, ha fatto crollare la guglia dello storico edificio, che era in fase di ristrutturazione. La guglia... Testo: Un incendio di vaste proporzioni nell'ex Borsa Valori di Copenaghen, risalente al XVII secolo, ha fatto crollare la guglia dello storico edificio, che era in fase di ristrutturazione., Fonte: ilmattino.it\n",
            "Titolo: Ponte sullo Stretto, i sindaci al ministero dell’Ambiente: «Dai cantieri all’opera, ecco tutti gli..., Summary: I sindaci di Villa San Giovanni e Messina dicono no alla riprogettazione in fase esecutiva. E chiedono al ministero dell’Ambiente studi, integrazioni e quantificazioni per valutare a breve, medio e lungo periodo gli effetti dei lavori sulle città e le comunità Testo: O quello del forte murattiano, forte Beleno, risalente al 1880, che rischia di essere cancellato dalla costruzione del ponte., Fonte: ilsole24ore.com\n",
            "Titolo: Casting per un film nel comitato elettorale della destra a Volterra. È polemica sui provini ‘acchiappa voti’, Summary: L’iniziativa nella sede del comitato della candidata sindaca civica sostenuta dal centrodestra Francesca Giorli che lavora nel settore del cinema. Una commistione tra una possibilità di lavoro e una elezione locale Testo: Succede a Volterra, in provincia di Pisa., Fonte: repubblica.it\n",
            "Titolo: Maltempo, frane in Trentino e in Friuli. Neve rossa su Marmolada. Torna il sole a Milano, Summary: Resta ancora instabile il meteo in Lombardia ma l’ondata di maltempo prevista per Pasqua sulla regione è in attenuazione e le piogge della notte sono state meno intense di quanto previsto Testo: La più imponente sul passo del Turchino, che ha determinato la chiusura della strada, in località Fado, nel Genovese., Fonte: ilsole24ore.com\n",
            "Titolo: Baltimora, una nave cargo urta un ponte che crolla in acqua, Summary: nan Testo: A Baltimora, Maryland, una nave portacontainer ha urtato il ponte Key Bridge facendolo crollare., Fonte: repubblica.it\n",
            "Titolo: Eredità Agnelli, cinque lettere inguaiano Elkann. Una è all’attenzione dei pm: «Grazie per le quote della Dice, Summary: Ci sono cinque lettere che secondo gli inquirenti dimostrano «la risalenza (nel tempo, ndr) della strategia delittuoso-evasiva fondata sulla fittizia residenza estera di Marella... Testo: E, venendo meno il principio della residenza all’estero della Caracciolo, tutto il castello rischia di crollare., Fonte: ilmattino.it\n",
            "Titolo: Napoli, a San Martino via ai lavori: «Addio palizzata di legno», Summary: Dal Vomero, tramortito dai guai delle voragini e degli sprofondamenti, arriva anche una buona notizia. Sono appena iniziati i lavori per eliminare l?orribile palizzata in legno che, dal 2015,... Testo: Sono appena iniziati i lavori per eliminare l’orribile palizzata in legno che, dal 2015, sostiene il muro di cinta di Castel Sant’Elmo pericolante e sfregia il piazzale panoramico più bello della città., Fonte: ilmattino.it\n",
            "Titolo: Crolla una palazzina a Canale Monterano, tre estratti vivi dalle macerie, Summary: Il comune si trova a circa 70 chilometri dalla Capitale Testo: Una palazzina di due piani è crollata questa mattina a Canale Monterano, in provincia di Roma, vicino al lago di Bolsena., Fonte: ilsole24ore.com\n",
            ".assistant\n",
            "\n",
            "La Torre di Pisa non cadrà, non ci sono previsioni o minacce di crollo. La struttura è sottoposta a monitoraggio costante e a lavori di consolidamento per preservarne l'integrità.\n",
            " Ronaldo è mussulmano?\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " Ronaldo è mussulmano? sei sicuro? non farti ingannare dal fatto che si chiami Cristiano\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " Ronaldo è mussulmano? sei sicuro? non farti ingannare dal fatto che si chiami Cristiano quindi è gay?\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run dashboard.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}